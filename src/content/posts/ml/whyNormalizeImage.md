---
title: 为什么可以归一化
published: 2025-06-14
description: 突发奇想, 似乎解释了关于数据处理时, 为什么图片可以归一化的问题.
tags: [Computer Vision, ML]
category: ML
draft: false
---

突发奇想, 似乎解释了关于数据处理时, 为什么图片可以归一化的问题.

<!--more-->

## 一些答案

1. 因为ImageNet的均值和方差是这样，这是个经验规律，这么做的结果一般都不错。
2. 因为归一化之后有利于评估模型，各种模型都有统一的评估指标。

两种解答都很合理，第一种告诉我们是经验，第二种告诉我们是评估上更加方便。
然而，各种模型本身有特殊评估指标，mIoU、置信度、精确度、top-5 score等等，
似乎都是与数据集是什么范围关系不大，那何来有利于评估模型一说？这些解答不能满足我。

## Why

我的想法是，对于深度神经网络，学习的本质是数据的规律，
而不是数据本身，这很重要。既然是规律，那么任何数据经过恒等变换之后继续学习不会有区别，因为可以逆变换回去。
对于经典CNN图像分类，总是把图像做normalize，那图像的rgb都不一样了，真的对吗？其实不做normalize，我的模型似乎也没啥大问题呀？
然而细究就发现，normalize是恒等变换，也就是说，它不改变数据的规律，而模型只是要学习数据的规律，而不是数据本身。
在这个例子下，模型学习的是图像潜在的组成规律，而不是rgb值。

那为什么做了normalize反而模型效果经验上要更好？如果不做normalize，一张图像的数据范围是(0, 255)，做之后是(0, 1)，
前者的数值更容易不稳定，或者在梯度上产生较大不应该的变化而且被保留，难以泛化，而后者数值更稳定，梯度的变化不会太大，
更取决于浮点精度，泛化能力会明显更强。
